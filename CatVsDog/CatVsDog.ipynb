{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a185c2",
   "metadata": {},
   "source": [
    "# Cats Vs Dogs\n",
    "I'm going to use [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) to finetune a pre-existing model to differentiate between Cats and Dogs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2b89d5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3433e5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4022ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce15f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d527ff",
   "metadata": {},
   "source": [
    "**This file is intended to run on Google Colab**\n",
    "\n",
    "Check if GPU is available, if not change the runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9fdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66facf3",
   "metadata": {},
   "source": [
    "## Download the Data\n",
    "\n",
    "The data from [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) consists of two files: images.tar.gz and annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5188fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir data\n",
    "#%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2edfeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "#!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dfd17a",
   "metadata": {},
   "source": [
    "Extract the downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea342226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar zxvf images.tar.gz\n",
    "#!tar zxvf annotations.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b388547",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c796b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b331a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f71ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head annotations/test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head annotations/trainval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5966f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir test trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb77b2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dd67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def check_dir(dir_path):\n",
    "    dir_path = dir_path.replace('//','/')\n",
    "    os.makedirs(dir_path, exist_ok=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "#Load Regex\n",
    "pat = re.compile(r'_\\d')\n",
    "pwd = os.getcwd()\n",
    "#define data wrangler function to format file system in desired order\n",
    "def data_wrangle(folder, lowercase):\n",
    "    #iterate through test file for list images to save to test dir\n",
    "    with open(f'./annotations/{folder}.txt') as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            f,_,_,_ = line.split(' ')\n",
    "            res,_ = pat.split(f)\n",
    "            line = fp.readline()\n",
    "            path = os.path.join(pwd,f\"{folder}/\",res)\n",
    "            src = os.path.join(pwd,\"images/\",f\"{f}.jpg\")\n",
    "            if not lowercase and not res.islower():\n",
    "                check_dir(path)\n",
    "                print(\"path '%s' created\" %path)\n",
    "                path = os.path.join(pwd,f\"{folder}/{res}\",f\"{f}.jpg\")\n",
    "                shutil.copy(src, path)\n",
    "                print(f\"file from {src} copied to {path}\")\n",
    "            elif lowercase and res.islower():\n",
    "                check_dir(path)\n",
    "                print(\"path '%s' created\" %path)\n",
    "                path = os.path.join(pwd,f\"{folder}/{res}\",f\"{f}.jpg\")\n",
    "                shutil.copy(src, path)\n",
    "                print(f\"file from {src} copied to {path}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wrangle(\"test\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wrangle(\"test\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wrangle(\"trainval\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddaa405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_wrangle(\"trainval\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe2e17",
   "metadata": {},
   "source": [
    "# DO NOT RUN ABOVE CODE AGAIN\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28bdd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls trainval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9c850",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cdd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls data\n",
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da277bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models, transforms, datasets\n",
    "import time\n",
    "import os\n",
    "data_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5afe96",
   "metadata": {},
   "source": [
    "All images need to be the same size to work with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ab2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "vgg_format = transforms.Compose([\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), vgg_format)\n",
    "        for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db34d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(data_dir, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ac6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe11184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a888e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'test']}\n",
    "dset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_classes = dsets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10e0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = torch.utils.data.DataLoader(dsets['train'], batch_size = 8, shuffle = True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a075ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#?torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_valid = torch.utils.data.DataLoader(dsets['test'], batch_size = 8, shuffle = True, num_workers=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6805fff",
   "metadata": {},
   "source": [
    "Check DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "for data in loader_valid:\n",
    "    print(count, end=',')\n",
    "    if count == 1:\n",
    "        inputs_try,labels_try = data\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da03090",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7178f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_try.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d52c0",
   "metadata": {},
   "source": [
    "Defining function to display images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "#   Imshow for Tensor.\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = np.clip(std * inp + mean, 0,1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b330d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs_try)\n",
    "\n",
    "imshow(out, title=[dset_classes[x] for x in labels_try])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d747a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(loader_train))\n",
    "\n",
    "n_images=8\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
    "\n",
    "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162291f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = models.vgg16(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8faa832",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "inputs_try , labels_try = inputs_try.to(device), labels_try.to(device)\n",
    "\n",
    "model_vgg = model_vgg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b1ff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_try = model_vgg(inputs_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcbcd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_try.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8eb672",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "    model_vgg.classifier._modules['6'] = nn.Linear(4096,37)\n",
    "    model_vgg.classifier._modules['7'] = torch.nn.LogSoftmax(dim = 1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e481459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_vgg.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5552c7a7",
   "metadata": {},
   "source": [
    "Load Model onto device(GPU,CPU,TPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = model_vgg.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421d4b8f",
   "metadata": {},
   "source": [
    "# Training Fully Connected Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50c0e76",
   "metadata": {},
   "source": [
    "## Creating loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01fc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "lr = 0.001\n",
    "optimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5c962e",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,dataloader,size,epochs=1,optimizer=None):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        for inputs,classes in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            classes = classes.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs,classes)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == classes.data)\n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects.data.item() / size\n",
    "        print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch_loss, epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c884f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model(model_vgg,loader_train,size=dset_sizes['train'],epochs=2,optimizer=optimizer_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fd499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model,dataloader,size):\n",
    "    model.eval()\n",
    "    predictions = np.zeros(size)\n",
    "    all_classes = np.zeros(size)\n",
    "    all_proba = np.zeros((size,37))\n",
    "    i = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    #print(size)\n",
    "    for inputs,classes in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,classes)           \n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "        running_loss += loss.data.item()\n",
    "        running_corrects += torch.sum(preds == classes.data)\n",
    "        predictions[i:i+len(classes)] = preds.to('cpu').numpy()\n",
    "        all_classes[i:i+len(classes)] = classes.to('cpu').numpy()\n",
    "        all_proba[i:i+len(classes),:] = outputs.data.to('cpu').numpy()\n",
    "        i += len(classes)\n",
    "    epoch_loss = running_loss / size\n",
    "    epoch_acc = running_corrects.data.item() / size\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch_loss, epoch_acc))\n",
    "    return predictions, all_proba, all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b30c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, all_proba, all_classes = test_model(model_vgg,loader_valid,size=dset_sizes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd84366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(loader_valid))\n",
    "\n",
    "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
    "\n",
    "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae16ffe",
   "metadata": {},
   "source": [
    "Compute the predictions made by your network for inputs[:n_images] and the associated probabilities.\n",
    "\n",
    "Hint: use torch.max and torch.exp.\n",
    "\n",
    "Do not forget to put your inputs on the device!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad27a82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_vgg(inputs[:n_images].to(device))\n",
    "print(torch.exp(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be815eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_try, preds_try = torch.max(outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6199de",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[:n_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(vals_try)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d63567f",
   "metadata": {},
   "source": [
    "# Speeding up the learning process by precomputing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0c82f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat(dataloader):\n",
    "    conv_features = []\n",
    "    labels_list = []\n",
    "    for data in dataloader:\n",
    "        inputs,labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        x = model_vgg.features(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        labels_list.extend(labels.data.cpu().numpy())\n",
    "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
    "    return (conv_features,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc55f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conv_feat_train,labels_train = preconvfeat(loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac26c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conv_feat_valid,labels_valid = preconvfeat(loader_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccafd425",
   "metadata": {},
   "source": [
    "# Creating a new data generator\n",
    "we will not load images anymore, so we need to build our own data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedffb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype=torch.float\n",
    "datasetfeat_train = [[torch.from_numpy(f).type(dtype),torch.tensor(l).type(torch.long)] for (f,l) in zip(conv_feat_train,labels_train)]\n",
    "datasetfeat_train = [(inputs.reshape(-1), classes) for [inputs,classes] in datasetfeat_train]\n",
    "loaderfeat_train = torch.utils.data.DataLoader(datasetfeat_train, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1615e4c8",
   "metadata": {},
   "source": [
    "now you can train for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model(model_vgg.classifier,dataloader=loaderfeat_train,size=dset_sizes['train'],epochs=80,optimizer=optimizer_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetfeat_valid = [[torch.from_numpy(f).type(dtype),torch.tensor(l).type(torch.long)] for (f,l) in zip(conv_feat_valid,labels_valid)]\n",
    "datasetfeat_valid = [(inputs.reshape(-1), classes) for [inputs,classes] in datasetfeat_valid]\n",
    "loaderfeat_valid = torch.utils.data.DataLoader(datasetfeat_valid, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb2a77",
   "metadata": {},
   "source": [
    "Now you can compute the accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, all_proba, all_classes = test_model(model_vgg.classifier,dataloader=loaderfeat_valid,size=dset_sizes['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1649bc",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "For 37 classes, plotting a confusion matrix is useful to see the performance of the algorithm per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff5a6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713f07b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def make_fig_cm(cm):\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    tick_marks = np.arange(37);\n",
    "    plt.xticks(tick_marks, dset_classes, rotation=90);\n",
    "    plt.yticks(tick_marks, dset_classes, rotation=0);\n",
    "    plt.tight_layout();\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        coeff = f'{cm[i, j]}'\n",
    "        plt.text(j, i, coeff, horizontalalignment=\"center\", verticalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('Actual');\n",
    "    plt.xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f916cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_classes,predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669798ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_fig_cm(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ea808",
   "metadata": {},
   "source": [
    "Here, you see that american pit bull terrier are often predicted as staffordshire bull terrier but overall the algorithm gives pretty good results!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0935bd5e",
   "metadata": {},
   "source": [
    "Now, I will take a resnet34 model to modify it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model_resnet = torchvision.models.resnet34(weights='DEFAULT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4af5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2550a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_resnet.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17920fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df3055",
   "metadata": {},
   "source": [
    "replace the last layer to 1000 inputs and 37 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a419269",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.eval()\n",
    "for param in model_resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "# your code here\n",
    "model_resnet.fc = nn.Linear(512, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c606b31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_resnet.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9829ca69",
   "metadata": {},
   "source": [
    "Create a soft max layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet_lsm = nn.Sequential(model_resnet, torch.nn.LogSoftmax(dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bcb987",
   "metadata": {},
   "source": [
    "check everything is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0154a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_try , labels_try = inputs_try.to(device), labels_try.to(device)\n",
    "model_resnet_lsm = model_resnet_lsm.to(device)\n",
    "outputs_try = model_resnet_lsm(inputs_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_try.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d8879",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_resnet_lsm[0].fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer_resnet = torch.optim.SGD(model_resnet_lsm[0].fc.parameters(),lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f582ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_model(model_resnet_lsm,loader_train,size=dset_sizes['train'],epochs=30,optimizer=optimizer_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8363af08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions, all_proba, all_classes = test_model(model_resnet_lsm,loader_valid,size=dset_sizes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_classes,predictions)\n",
    "make_fig_cm(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
